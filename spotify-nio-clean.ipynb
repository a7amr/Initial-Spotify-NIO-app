{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4372070,"sourceType":"datasetVersion","datasetId":2570056}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"c5b81c9c","cell_type":"code","source":"# CELL 1: imports & basic setup\n\nimport os\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\nprint(\"Torch version:\", torch.__version__)\nprint(\"CUDA available:\", torch.cuda.is_available())\n","metadata":{"execution":{"iopub.status.busy":"2025-12-03T23:53:13.296351Z","iopub.execute_input":"2025-12-03T23:53:13.296540Z","iopub.status.idle":"2025-12-03T23:53:19.842661Z","shell.execute_reply.started":"2025-12-03T23:53:13.296524Z","shell.execute_reply":"2025-12-03T23:53:19.841790Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Torch version: 2.6.0+cu124\nCUDA available: True\n","output_type":"stream"}],"execution_count":1},{"id":"6534aa8b","cell_type":"code","source":"# CELL 2: detect Spotify folder and load CSV\n\nbase_input = \"/kaggle/input\"\nprint(\"Folders in /kaggle/input:\")\nprint(os.listdir(base_input))\n\n# Try to auto-detect a folder with \"spotify\" in the name\nspotify_dirs = [d for d in os.listdir(base_input) if \"spotify\" in d.lower()]\nprint(\"\\nDetected Spotify-like folders:\", spotify_dirs)\n\nif not spotify_dirs:\n    raise RuntimeError(\n        \"No folder with 'spotify' in its name was found in /kaggle/input. \"\n        \"Make sure you've added the Spotify Tracks dataset to this notebook.\"\n    )\n\nDATA_PATH = os.path.join(base_input, spotify_dirs[0])\nprint(\"\\nUsing DATA_PATH:\", DATA_PATH)\n\n# Find a CSV in that folder\ncsv_files = [f for f in os.listdir(DATA_PATH) if f.lower().endswith(\".csv\")]\nprint(\"CSV files in DATA_PATH:\", csv_files)\n\nif not csv_files:\n    raise RuntimeError(\"No CSV files found inside DATA_PATH.\")\n\nCSV_FILE = csv_files[0]\nprint(\"Using CSV_FILE:\", CSV_FILE)\n\ndf = pd.read_csv(os.path.join(DATA_PATH, CSV_FILE))\nprint(\"\\nRaw shape:\", df.shape)\ndf.head()\n","metadata":{"execution":{"iopub.status.busy":"2025-12-03T23:53:19.844458Z","iopub.execute_input":"2025-12-03T23:53:19.844821Z","iopub.status.idle":"2025-12-03T23:53:20.759712Z","shell.execute_reply.started":"2025-12-03T23:53:19.844801Z","shell.execute_reply":"2025-12-03T23:53:20.759107Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Folders in /kaggle/input:\n['-spotify-tracks-dataset']\n\nDetected Spotify-like folders: ['-spotify-tracks-dataset']\n\nUsing DATA_PATH: /kaggle/input/-spotify-tracks-dataset\nCSV files in DATA_PATH: ['dataset.csv']\nUsing CSV_FILE: dataset.csv\n\nRaw shape: (114000, 21)\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                track_id                 artists  \\\n0           0  5SuOikwiRyPMVoIQDJUgSV             Gen Hoshino   \n1           1  4qPNDBW1i3p13qLCt0Ki3A            Ben Woodward   \n2           2  1iJBSr7s7jYXzM8EGcbK5b  Ingrid Michaelson;ZAYN   \n3           3  6lfxq3CG4xtTiEg7opyCyx            Kina Grannis   \n4           4  5vjLSffimiIP26QG5WcN2K        Chord Overstreet   \n\n                                          album_name  \\\n0                                             Comedy   \n1                                   Ghost (Acoustic)   \n2                                     To Begin Again   \n3  Crazy Rich Asians (Original Motion Picture Sou...   \n4                                            Hold On   \n\n                   track_name  popularity  duration_ms  explicit  \\\n0                      Comedy          73       230666     False   \n1            Ghost - Acoustic          55       149610     False   \n2              To Begin Again          57       210826     False   \n3  Can't Help Falling In Love          71       201933     False   \n4                     Hold On          82       198853     False   \n\n   danceability  energy  ...  loudness  mode  speechiness  acousticness  \\\n0         0.676  0.4610  ...    -6.746     0       0.1430        0.0322   \n1         0.420  0.1660  ...   -17.235     1       0.0763        0.9240   \n2         0.438  0.3590  ...    -9.734     1       0.0557        0.2100   \n3         0.266  0.0596  ...   -18.515     1       0.0363        0.9050   \n4         0.618  0.4430  ...    -9.681     1       0.0526        0.4690   \n\n   instrumentalness  liveness  valence    tempo  time_signature  track_genre  \n0          0.000001    0.3580    0.715   87.917               4     acoustic  \n1          0.000006    0.1010    0.267   77.489               4     acoustic  \n2          0.000000    0.1170    0.120   76.332               4     acoustic  \n3          0.000071    0.1320    0.143  181.740               3     acoustic  \n4          0.000000    0.0829    0.167  119.949               4     acoustic  \n\n[5 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>track_id</th>\n      <th>artists</th>\n      <th>album_name</th>\n      <th>track_name</th>\n      <th>popularity</th>\n      <th>duration_ms</th>\n      <th>explicit</th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>...</th>\n      <th>loudness</th>\n      <th>mode</th>\n      <th>speechiness</th>\n      <th>acousticness</th>\n      <th>instrumentalness</th>\n      <th>liveness</th>\n      <th>valence</th>\n      <th>tempo</th>\n      <th>time_signature</th>\n      <th>track_genre</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>5SuOikwiRyPMVoIQDJUgSV</td>\n      <td>Gen Hoshino</td>\n      <td>Comedy</td>\n      <td>Comedy</td>\n      <td>73</td>\n      <td>230666</td>\n      <td>False</td>\n      <td>0.676</td>\n      <td>0.4610</td>\n      <td>...</td>\n      <td>-6.746</td>\n      <td>0</td>\n      <td>0.1430</td>\n      <td>0.0322</td>\n      <td>0.000001</td>\n      <td>0.3580</td>\n      <td>0.715</td>\n      <td>87.917</td>\n      <td>4</td>\n      <td>acoustic</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>4qPNDBW1i3p13qLCt0Ki3A</td>\n      <td>Ben Woodward</td>\n      <td>Ghost (Acoustic)</td>\n      <td>Ghost - Acoustic</td>\n      <td>55</td>\n      <td>149610</td>\n      <td>False</td>\n      <td>0.420</td>\n      <td>0.1660</td>\n      <td>...</td>\n      <td>-17.235</td>\n      <td>1</td>\n      <td>0.0763</td>\n      <td>0.9240</td>\n      <td>0.000006</td>\n      <td>0.1010</td>\n      <td>0.267</td>\n      <td>77.489</td>\n      <td>4</td>\n      <td>acoustic</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1iJBSr7s7jYXzM8EGcbK5b</td>\n      <td>Ingrid Michaelson;ZAYN</td>\n      <td>To Begin Again</td>\n      <td>To Begin Again</td>\n      <td>57</td>\n      <td>210826</td>\n      <td>False</td>\n      <td>0.438</td>\n      <td>0.3590</td>\n      <td>...</td>\n      <td>-9.734</td>\n      <td>1</td>\n      <td>0.0557</td>\n      <td>0.2100</td>\n      <td>0.000000</td>\n      <td>0.1170</td>\n      <td>0.120</td>\n      <td>76.332</td>\n      <td>4</td>\n      <td>acoustic</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>6lfxq3CG4xtTiEg7opyCyx</td>\n      <td>Kina Grannis</td>\n      <td>Crazy Rich Asians (Original Motion Picture Sou...</td>\n      <td>Can't Help Falling In Love</td>\n      <td>71</td>\n      <td>201933</td>\n      <td>False</td>\n      <td>0.266</td>\n      <td>0.0596</td>\n      <td>...</td>\n      <td>-18.515</td>\n      <td>1</td>\n      <td>0.0363</td>\n      <td>0.9050</td>\n      <td>0.000071</td>\n      <td>0.1320</td>\n      <td>0.143</td>\n      <td>181.740</td>\n      <td>3</td>\n      <td>acoustic</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>5vjLSffimiIP26QG5WcN2K</td>\n      <td>Chord Overstreet</td>\n      <td>Hold On</td>\n      <td>Hold On</td>\n      <td>82</td>\n      <td>198853</td>\n      <td>False</td>\n      <td>0.618</td>\n      <td>0.4430</td>\n      <td>...</td>\n      <td>-9.681</td>\n      <td>1</td>\n      <td>0.0526</td>\n      <td>0.4690</td>\n      <td>0.000000</td>\n      <td>0.0829</td>\n      <td>0.167</td>\n      <td>119.949</td>\n      <td>4</td>\n      <td>acoustic</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"},"metadata":{}}],"execution_count":2},{"id":"03cd44aa","cell_type":"code","source":"# CELL 3: quick EDA – columns, dtypes, popularity stats\n\nprint(\"Columns:\\n\", df.columns.tolist())\nprint(\"\\nDtypes:\\n\", df.dtypes)\n\nif \"popularity\" not in df.columns:\n    raise RuntimeError(\"No 'popularity' column found. Check the dataset columns.\")\n\nprint(\"\\nPopularity stats:\")\nprint(df[\"popularity\"].describe())\n\nprint(\"\\nMissing values (top 15):\")\nprint(df.isna().sum().sort_values(ascending=False).head(15))\n","metadata":{"execution":{"iopub.status.busy":"2025-12-03T23:53:20.763431Z","iopub.execute_input":"2025-12-03T23:53:20.763674Z","iopub.status.idle":"2025-12-03T23:53:20.810496Z","shell.execute_reply.started":"2025-12-03T23:53:20.763656Z","shell.execute_reply":"2025-12-03T23:53:20.809761Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Columns:\n ['Unnamed: 0', 'track_id', 'artists', 'album_name', 'track_name', 'popularity', 'duration_ms', 'explicit', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature', 'track_genre']\n\nDtypes:\n Unnamed: 0            int64\ntrack_id             object\nartists              object\nalbum_name           object\ntrack_name           object\npopularity            int64\nduration_ms           int64\nexplicit               bool\ndanceability        float64\nenergy              float64\nkey                   int64\nloudness            float64\nmode                  int64\nspeechiness         float64\nacousticness        float64\ninstrumentalness    float64\nliveness            float64\nvalence             float64\ntempo               float64\ntime_signature        int64\ntrack_genre          object\ndtype: object\n\nPopularity stats:\ncount    114000.000000\nmean         33.238535\nstd          22.305078\nmin           0.000000\n25%          17.000000\n50%          35.000000\n75%          50.000000\nmax         100.000000\nName: popularity, dtype: float64\n\nMissing values (top 15):\nartists         1\ntrack_name      1\nalbum_name      1\nUnnamed: 0      0\ntrack_id        0\npopularity      0\nduration_ms     0\nexplicit        0\ndanceability    0\nenergy          0\nkey             0\nloudness        0\nmode            0\nspeechiness     0\nacousticness    0\ndtype: int64\n","output_type":"stream"}],"execution_count":3},{"id":"02383161","cell_type":"code","source":"# CELL 4: basic cleaning\n\nprint(\"Original shape:\", df.shape)\n\n# Drop exact duplicate rows\ndf = df.drop_duplicates()\nprint(\"After dropping duplicates:\", df.shape)\n\n# (Optional) Drop rows with missing popularity, if any\ndf = df.dropna(subset=[\"popularity\"])\nprint(\"After dropping rows with missing popularity:\", df.shape)\n\n# If there are still missing values in other columns, we'll handle below\nprint(\"\\nRemaining missing values (top 15):\")\nprint(df.isna().sum().sort_values(ascending=False).head(15))\n","metadata":{"execution":{"iopub.status.busy":"2025-12-03T23:53:20.811374Z","iopub.execute_input":"2025-12-03T23:53:20.812029Z","iopub.status.idle":"2025-12-03T23:53:20.976856Z","shell.execute_reply.started":"2025-12-03T23:53:20.811997Z","shell.execute_reply":"2025-12-03T23:53:20.976260Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Original shape: (114000, 21)\nAfter dropping duplicates: (114000, 21)\nAfter dropping rows with missing popularity: (114000, 21)\n\nRemaining missing values (top 15):\nartists         1\ntrack_name      1\nalbum_name      1\nUnnamed: 0      0\ntrack_id        0\npopularity      0\nduration_ms     0\nexplicit        0\ndanceability    0\nenergy          0\nkey             0\nloudness        0\nmode            0\nspeechiness     0\nacousticness    0\ndtype: int64\n","output_type":"stream"}],"execution_count":4},{"id":"06b77881","cell_type":"code","source":"# CELL 5: feature/target setup + preprocessing\n\ntarget_col = \"popularity\"\n\n# Columns that are pure IDs / names (no direct numeric meaning for regression)\ndrop_id_cols = [\"track_id\", \"artists\", \"album_name\", \"track_name\"]\n\n# Drop only those ID columns that actually exist\ndrop_id_cols = [c for c in drop_id_cols if c in df.columns]\n\nprint(\"Dropping ID/text columns:\", drop_id_cols)\n\nX = df.drop(columns=[target_col] + drop_id_cols)\ny = df[target_col].astype(np.float32).values\n\nprint(\"X shape before encoding:\", X.shape)\nprint(\"Example columns:\", X.columns.tolist()[:15])\n\n# One-hot encode non-numeric columns automatically\nX_encoded = pd.get_dummies(X, drop_first=True)\n\nprint(\"X_encoded shape after get_dummies:\", X_encoded.shape)\n\n# Fill any remaining missing numeric values with column median\nX_encoded = X_encoded.fillna(X_encoded.median(numeric_only=True))\n\n# Scale features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X_encoded).astype(np.float32)\n\ny = y.astype(np.float32)\n\nprint(\"Final X_scaled shape:\", X_scaled.shape)\nprint(\"y shape:\", y.shape)\n","metadata":{"execution":{"iopub.status.busy":"2025-12-03T23:53:20.977532Z","iopub.execute_input":"2025-12-03T23:53:20.977738Z","iopub.status.idle":"2025-12-03T23:53:21.777772Z","shell.execute_reply.started":"2025-12-03T23:53:20.977720Z","shell.execute_reply":"2025-12-03T23:53:21.777124Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Dropping ID/text columns: ['track_id', 'artists', 'album_name', 'track_name']\nX shape before encoding: (114000, 16)\nExample columns: ['Unnamed: 0', 'duration_ms', 'explicit', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature']\nX_encoded shape after get_dummies: (114000, 128)\nFinal X_scaled shape: (114000, 128)\ny shape: (114000,)\n","output_type":"stream"}],"execution_count":5},{"id":"5df06353","cell_type":"code","source":"# CELL 6: train/val/test split\n\n# First: train+val vs test\nX_train_val, X_test, y_train_val, y_test = train_test_split(\n    X_scaled, y, test_size=0.15, random_state=42\n)\n\n# Then: split train_val into train and val\nval_size = 0.1765  # ~15% of total (0.1765 * 0.85 ≈ 0.15)\nX_train, X_val, y_train, y_val = train_test_split(\n    X_train_val, y_train_val, test_size=val_size, random_state=42\n)\n\nprint(\"Train:\", X_train.shape, y_train.shape)\nprint(\"Val  :\", X_val.shape, y_val.shape)\nprint(\"Test :\", X_test.shape, y_test.shape)\n","metadata":{"execution":{"iopub.status.busy":"2025-12-03T23:53:21.779979Z","iopub.execute_input":"2025-12-03T23:53:21.780259Z","iopub.status.idle":"2025-12-03T23:53:21.918168Z","shell.execute_reply.started":"2025-12-03T23:53:21.780239Z","shell.execute_reply":"2025-12-03T23:53:21.917448Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Train: (79797, 128) (79797,)\nVal  : (17103, 128) (17103,)\nTest : (17100, 128) (17100,)\n","output_type":"stream"}],"execution_count":6},{"id":"667c4b3a","cell_type":"code","source":"# CELL X1: install & import xgboost\n\n!pip install xgboost --quiet\n\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport numpy as np\n","metadata":{"execution":{"iopub.status.busy":"2025-12-03T23:53:21.918901Z","iopub.execute_input":"2025-12-03T23:53:21.919191Z","iopub.status.idle":"2025-12-03T23:53:26.254097Z","shell.execute_reply.started":"2025-12-03T23:53:21.919171Z","shell.execute_reply":"2025-12-03T23:53:26.253218Z"},"trusted":true},"outputs":[],"execution_count":7},{"id":"60f80ae9","cell_type":"code","source":"# CELL X2: prepare DMatrix for train/val/test\n\ndtrain = xgb.DMatrix(X_train, label=y_train)\ndval   = xgb.DMatrix(X_val,   label=y_val)\ndtest  = xgb.DMatrix(X_test,  label=y_test)\n","metadata":{"execution":{"iopub.status.busy":"2025-12-03T23:53:26.255090Z","iopub.execute_input":"2025-12-03T23:53:26.255355Z","iopub.status.idle":"2025-12-03T23:53:26.435274Z","shell.execute_reply.started":"2025-12-03T23:53:26.255329Z","shell.execute_reply":"2025-12-03T23:53:26.434472Z"},"trusted":true},"outputs":[],"execution_count":8},{"id":"063a03db","cell_type":"code","source":"# HY1: small manual hyperparameter search for XGBoost\n\nimport xgboost as xgb\nimport numpy as np\nfrom sklearn.metrics import mean_squared_error, r2_score\n\ndef train_and_eval(params_base, extra_params, dtrain, dval, dtest, num_boost_round=2000):\n    params = params_base.copy()\n    params.update(extra_params)\n\n    evals = [(dtrain, \"train\"), (dval, \"val\")]\n\n    model = xgb.train(\n        params,\n        dtrain,\n        num_boost_round=num_boost_round,\n        evals=evals,\n        early_stopping_rounds=50,\n        verbose_eval=False,  # set to 100 if you want logs\n    )\n\n    # Best val RMSE is stored in model.best_score\n    val_rmse = float(model.best_score)\n\n    # Test metrics\n    y_pred_test = model.predict(dtest, iteration_range=(0, model.best_iteration + 1))\n    rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n    r2_test   = r2_score(y_test, y_pred_test)\n\n    return model, val_rmse, rmse_test, r2_test\n\n# Base params (same style as before)\nbase_params = {\n    \"objective\": \"reg:squarederror\",\n    \"eval_metric\": \"rmse\",\n    \"eta\": 0.05,\n    \"lambda\": 1.0,\n    \"alpha\": 0.0,\n}\n\n# A small list of candidate hyperparameter combos\nparam_candidates = [\n    {\"max_depth\": 6, \"min_child_weight\": 1, \"subsample\": 0.8, \"colsample_bytree\": 0.8, \"gamma\": 0.0},\n    {\"max_depth\": 8, \"min_child_weight\": 1, \"subsample\": 0.8, \"colsample_bytree\": 0.8, \"gamma\": 0.0},\n    {\"max_depth\": 10,\"min_child_weight\": 1, \"subsample\": 0.8, \"colsample_bytree\": 0.8, \"gamma\": 0.0},\n    {\"max_depth\": 8, \"min_child_weight\": 5, \"subsample\": 0.8, \"colsample_bytree\": 0.8, \"gamma\": 0.0},\n    {\"max_depth\": 8, \"min_child_weight\": 1, \"subsample\": 0.7, \"colsample_bytree\": 0.9, \"gamma\": 0.0},\n    {\"max_depth\": 8, \"min_child_weight\": 1, \"subsample\": 0.9, \"colsample_bytree\": 0.7, \"gamma\": 0.0},\n    {\"max_depth\": 8, \"min_child_weight\": 1, \"subsample\": 0.9, \"colsample_bytree\": 0.9, \"gamma\": 0.0},\n    {\"max_depth\": 8, \"min_child_weight\": 1, \"subsample\": 0.8, \"colsample_bytree\": 0.8, \"gamma\": 1.0},\n]\n\nresults = []\nbest_model = None\nbest_val_rmse = float(\"inf\")\n\nfor i, extra in enumerate(param_candidates):\n    print(f\"\\n=== Candidate {i+1}/{len(param_candidates)}: {extra} ===\")\n    model_i, val_rmse_i, rmse_test_i, r2_test_i = train_and_eval(\n        base_params, extra, dtrain, dval, dtest\n    )\n    print(f\"Val RMSE : {val_rmse_i:.2f}\")\n    print(f\"Test RMSE: {rmse_test_i:.2f}\")\n    print(f\"Test R²  : {r2_test_i:.3f}\")\n\n    results.append((extra, val_rmse_i, rmse_test_i, r2_test_i))\n\n    if val_rmse_i < best_val_rmse:\n        best_val_rmse = val_rmse_i\n        best_model = model_i\n\nprint(\"\\n=== Summary of candidates ===\")\nfor extra, val_rmse_i, rmse_test_i, r2_test_i in results:\n    print(f\"{extra} -> Val RMSE {val_rmse_i:.2f}, Test RMSE {rmse_test_i:.2f}, Test R² {r2_test_i:.3f}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-12-03T23:53:26.436147Z","iopub.execute_input":"2025-12-03T23:53:26.436420Z","iopub.status.idle":"2025-12-03T23:59:04.490237Z","shell.execute_reply.started":"2025-12-03T23:53:26.436400Z","shell.execute_reply":"2025-12-03T23:59:04.489511Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\n=== Candidate 1/8: {'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.0} ===\nVal RMSE : 15.91\nTest RMSE: 15.62\nTest R²  : 0.505\n\n=== Candidate 2/8: {'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.0} ===\nVal RMSE : 15.34\nTest RMSE: 14.99\nTest R²  : 0.544\n\n=== Candidate 3/8: {'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.0} ===\nVal RMSE : 15.07\nTest RMSE: 14.78\nTest R²  : 0.557\n\n=== Candidate 4/8: {'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.0} ===\nVal RMSE : 15.27\nTest RMSE: 14.92\nTest R²  : 0.549\n\n=== Candidate 5/8: {'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.9, 'gamma': 0.0} ===\nVal RMSE : 15.37\nTest RMSE: 15.02\nTest R²  : 0.543\n\n=== Candidate 6/8: {'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.7, 'gamma': 0.0} ===\nVal RMSE : 15.24\nTest RMSE: 14.95\nTest R²  : 0.547\n\n=== Candidate 7/8: {'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'gamma': 0.0} ===\nVal RMSE : 15.30\nTest RMSE: 14.97\nTest R²  : 0.546\n\n=== Candidate 8/8: {'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 1.0} ===\nVal RMSE : 15.31\nTest RMSE: 15.01\nTest R²  : 0.543\n\n=== Summary of candidates ===\n{'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.0} -> Val RMSE 15.91, Test RMSE 15.62, Test R² 0.505\n{'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.0} -> Val RMSE 15.34, Test RMSE 14.99, Test R² 0.544\n{'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.0} -> Val RMSE 15.07, Test RMSE 14.78, Test R² 0.557\n{'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.0} -> Val RMSE 15.27, Test RMSE 14.92, Test R² 0.549\n{'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.7, 'colsample_bytree': 0.9, 'gamma': 0.0} -> Val RMSE 15.37, Test RMSE 15.02, Test R² 0.543\n{'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.7, 'gamma': 0.0} -> Val RMSE 15.24, Test RMSE 14.95, Test R² 0.547\n{'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.9, 'gamma': 0.0} -> Val RMSE 15.30, Test RMSE 14.97, Test R² 0.546\n{'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 1.0} -> Val RMSE 15.31, Test RMSE 15.01, Test R² 0.543\n","output_type":"stream"}],"execution_count":9},{"id":"8e190fe7","cell_type":"code","source":"# HY2: save best XGBoost model from the search\n\nbest_model.save_model(\"spotify_xgb_best.json\")\nprint(\"Saved best XGBoost model.\")\n","metadata":{"execution":{"iopub.status.busy":"2025-12-03T23:59:04.490980Z","iopub.execute_input":"2025-12-03T23:59:04.491197Z","iopub.status.idle":"2025-12-03T23:59:05.517474Z","shell.execute_reply.started":"2025-12-03T23:59:04.491179Z","shell.execute_reply":"2025-12-03T23:59:05.516792Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Saved best XGBoost model.\n","output_type":"stream"}],"execution_count":10},{"id":"c089e1bc","cell_type":"code","source":"# CELL D1: teacher (XGBoost) predictions on train/val/test\n\nimport xgboost as xgb\nimport numpy as np\n\n# DMatrix without labels (labels aren't needed to predict)\ndtrain_no = xgb.DMatrix(X_train)\ndval_no   = xgb.DMatrix(X_val)\ndtest_no  = xgb.DMatrix(X_test)\n\ny_train_teacher = best_model.predict(dtrain_no)\ny_val_teacher   = best_model.predict(dval_no)\ny_test_teacher  = best_model.predict(dtest_no)\n\nprint(\"Teacher preds (train) shape:\", y_train_teacher.shape)\nprint(\"Teacher preds (val)   shape:\", y_val_teacher.shape)\nprint(\"Teacher preds (test)  shape:\", y_test_teacher.shape)\n\nprint(\"\\nTeacher train preds stats:\")\nprint(\"min:\", float(y_train_teacher.min()), \"max:\", float(y_train_teacher.max()))\nprint(\"mean:\", float(y_train_teacher.mean()))\n","metadata":{"execution":{"iopub.status.busy":"2025-12-03T23:59:05.518255Z","iopub.execute_input":"2025-12-03T23:59:05.518759Z","iopub.status.idle":"2025-12-03T23:59:11.875603Z","shell.execute_reply.started":"2025-12-03T23:59:05.518739Z","shell.execute_reply":"2025-12-03T23:59:11.874929Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Teacher preds (train) shape: (79797,)\nTeacher preds (val)   shape: (17103,)\nTeacher preds (test)  shape: (17100,)\n\nTeacher train preds stats:\nmin: -6.048275470733643 max: 98.70370483398438\nmean: 33.24055480957031\n","output_type":"stream"}],"execution_count":11},{"id":"fb802362","cell_type":"code","source":"# CELL SD1: larger student MLP for distillation\n\nimport torch\nimport torch.nn as nn\n\ninput_dim = X_train.shape[1]\nprint(\"Input dim:\", input_dim)\n\nclass SpotifyStudentMLP_Big(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, 768),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(768, 512),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Dropout(0.20),\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(0.10),\n            nn.Linear(128, 1)   # predicts teacher's popularity\n        )\n\n    def forward(self, x):\n        return self.net(x).squeeze(-1)\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nstudent_big = SpotifyStudentMLP_Big(input_dim).to(device)\n\nprint(student_big)\n","metadata":{"execution":{"iopub.status.busy":"2025-12-03T23:59:11.876387Z","iopub.execute_input":"2025-12-03T23:59:11.876603Z","iopub.status.idle":"2025-12-03T23:59:12.124869Z","shell.execute_reply.started":"2025-12-03T23:59:11.876586Z","shell.execute_reply":"2025-12-03T23:59:12.124110Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Input dim: 128\nSpotifyStudentMLP_Big(\n  (net): Sequential(\n    (0): Linear(in_features=128, out_features=768, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.25, inplace=False)\n    (3): Linear(in_features=768, out_features=512, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.25, inplace=False)\n    (6): Linear(in_features=512, out_features=256, bias=True)\n    (7): ReLU()\n    (8): Dropout(p=0.2, inplace=False)\n    (9): Linear(in_features=256, out_features=128, bias=True)\n    (10): ReLU()\n    (11): Dropout(p=0.1, inplace=False)\n    (12): Linear(in_features=128, out_features=1, bias=True)\n  )\n)\n","output_type":"stream"}],"execution_count":12},{"id":"dfda8528","cell_type":"code","source":"# H1: hybrid distillation dataset (true labels + teacher labels)\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\n\nclass SpotifyHybridDataset(Dataset):\n    def __init__(self, X, y_true, y_teacher):\n        self.X = torch.from_numpy(X)\n        self.y_true = torch.from_numpy(y_true.astype(np.float32))\n        self.y_teacher = torch.from_numpy(y_teacher.astype(np.float32))\n\n    def __len__(self):\n        return self.X.shape[0]\n\n    def __getitem__(self, idx):\n        return self.X[idx], self.y_true[idx], self.y_teacher[idx]\n\n\ntrain_hybrid_ds = SpotifyHybridDataset(X_train, y_train, y_train_teacher)\nval_hybrid_ds   = SpotifyHybridDataset(X_val,   y_val,   y_val_teacher)\ntest_hybrid_ds  = SpotifyHybridDataset(X_test,  y_test,  y_test_teacher)\n\ntrain_hybrid_loader = DataLoader(train_hybrid_ds, batch_size=512, shuffle=True)\nval_hybrid_loader   = DataLoader(val_hybrid_ds,   batch_size=2048, shuffle=False)\ntest_hybrid_loader  = DataLoader(test_hybrid_ds,  batch_size=2048, shuffle=False)\n\nlen(train_hybrid_ds), len(val_hybrid_ds), len(test_hybrid_ds)\n","metadata":{"execution":{"iopub.status.busy":"2025-12-03T23:59:12.125706Z","iopub.execute_input":"2025-12-03T23:59:12.126005Z","iopub.status.idle":"2025-12-03T23:59:12.139509Z","shell.execute_reply.started":"2025-12-03T23:59:12.125986Z","shell.execute_reply":"2025-12-03T23:59:12.138780Z"},"trusted":true},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(79797, 17103, 17100)"},"metadata":{}}],"execution_count":13},{"id":"ec92b632","cell_type":"code","source":"# H2: create a new hybrid student model (same architecture as big student)\n\nimport torch.nn as nn\n\ninput_dim = X_train.shape[1]\nprint(\"Input dim:\", input_dim)\n\nclass SpotifyStudentMLP_Big(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, 768),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(768, 512),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Dropout(0.20),\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(0.10),\n            nn.Linear(128, 1)\n        )\n\n    def forward(self, x):\n        return self.net(x).squeeze(-1)\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nstudent_hybrid = SpotifyStudentMLP_Big(input_dim).to(device)\n\nprint(student_hybrid)\n","metadata":{"execution":{"iopub.status.busy":"2025-12-03T23:59:12.140360Z","iopub.execute_input":"2025-12-03T23:59:12.140599Z","iopub.status.idle":"2025-12-03T23:59:12.158576Z","shell.execute_reply.started":"2025-12-03T23:59:12.140584Z","shell.execute_reply":"2025-12-03T23:59:12.158008Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Input dim: 128\nSpotifyStudentMLP_Big(\n  (net): Sequential(\n    (0): Linear(in_features=128, out_features=768, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.25, inplace=False)\n    (3): Linear(in_features=768, out_features=512, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.25, inplace=False)\n    (6): Linear(in_features=512, out_features=256, bias=True)\n    (7): ReLU()\n    (8): Dropout(p=0.2, inplace=False)\n    (9): Linear(in_features=256, out_features=128, bias=True)\n    (10): ReLU()\n    (11): Dropout(p=0.1, inplace=False)\n    (12): Linear(in_features=128, out_features=1, bias=True)\n  )\n)\n","output_type":"stream"}],"execution_count":14},{"id":"ad101790","cell_type":"code","source":"# H3: train hybrid student (true + teacher loss)\n\nfrom sklearn.metrics import mean_squared_error, r2_score\n\ndef rmse(y_true, y_pred):\n    return np.sqrt(mean_squared_error(y_true, y_pred))\n\nalpha = 0.6   # weight for TRUE labels vs teacher\n\ncriterion = nn.MSELoss(reduction=\"mean\")\noptimizer = torch.optim.AdamW(student_hybrid.parameters(), lr=1e-3, weight_decay=1e-4)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, mode=\"min\", factor=0.5, patience=3, verbose=True\n)\n\nnum_epochs = 120\nbest_val_rmse_true = float(\"inf\")\nbest_state_dict_h = None\npatience = 12\nepochs_no_improve = 0\n\nfor epoch in range(1, num_epochs + 1):\n    # ---- Train ----\n    student_hybrid.train()\n    train_losses = []\n\n    for xb, yb_true, yb_teacher in train_hybrid_loader:\n        xb = xb.to(device)\n        yb_true = yb_true.to(device)\n        yb_teacher = yb_teacher.to(device)\n\n        optimizer.zero_grad()\n        preds = student_hybrid(xb)\n        loss_true    = criterion(preds, yb_true)\n        loss_teacher = criterion(preds, yb_teacher)\n        loss = alpha * loss_true + (1 - alpha) * loss_teacher\n        loss.backward()\n        optimizer.step()\n\n        train_losses.append(loss.item())\n\n    train_loss = np.mean(train_losses)\n\n    # ---- Validate ----\n    student_hybrid.eval()\n    with torch.no_grad():\n        X_val_torch = torch.from_numpy(X_val).float().to(device)\n        val_preds = student_hybrid(X_val_torch).cpu().numpy()\n\n    # vs TRUE\n    val_rmse_true = rmse(y_val, val_preds)\n    val_r2_true   = r2_score(y_val, val_preds)\n\n    # vs TEACHER\n    val_rmse_teacher = rmse(y_val_teacher, val_preds)\n    val_r2_teacher   = r2_score(y_val_teacher, val_preds)\n\n    scheduler.step(val_rmse_true)\n\n    if val_rmse_true + 0.05 < best_val_rmse_true:\n        best_val_rmse_true = val_rmse_true\n        best_state_dict_h = student_hybrid.state_dict()\n        epochs_no_improve = 0\n    else:\n        epochs_no_improve += 1\n        if epochs_no_improve >= patience:\n            print(f\"Early stopping at epoch {epoch}.\")\n            break\n\n    if epoch == 1 or epoch % 5 == 0:\n        print(\n            f\"Epoch {epoch:03d} | \"\n            f\"Train Loss: {train_loss:.4f} | \"\n            f\"Val RMSE vs TRUE: {val_rmse_true:.2f} | \"\n            f\"Val R² vs TRUE: {val_r2_true:.3f} | \"\n            f\"Val RMSE vs TEACHER: {val_rmse_teacher:.2f} | \"\n            f\"Val R² vs TEACHER: {val_r2_teacher:.3f}\"\n        )\n\nprint(\"\\nBest validation RMSE vs TRUE (hybrid):\", best_val_rmse_true)\nif best_state_dict_h is not None:\n    student_hybrid.load_state_dict(best_state_dict_h)\n","metadata":{"execution":{"iopub.status.busy":"2025-12-03T23:59:12.159181Z","iopub.execute_input":"2025-12-03T23:59:12.159359Z","iopub.status.idle":"2025-12-04T00:00:47.009557Z","shell.execute_reply.started":"2025-12-03T23:59:12.159345Z","shell.execute_reply":"2025-12-04T00:00:47.008923Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 001 | Train Loss: 422.4624 | Val RMSE vs TRUE: 19.45 | Val R² vs TRUE: 0.245 | Val RMSE vs TEACHER: 12.67 | Val R² vs TEACHER: 0.423\nEpoch 005 | Train Loss: 334.1342 | Val RMSE vs TRUE: 19.25 | Val R² vs TRUE: 0.261 | Val RMSE vs TEACHER: 12.41 | Val R² vs TEACHER: 0.447\nEpoch 010 | Train Loss: 323.7138 | Val RMSE vs TRUE: 18.84 | Val R² vs TRUE: 0.292 | Val RMSE vs TEACHER: 11.60 | Val R² vs TEACHER: 0.517\nEpoch 015 | Train Loss: 318.2666 | Val RMSE vs TRUE: 18.82 | Val R² vs TRUE: 0.293 | Val RMSE vs TEACHER: 11.51 | Val R² vs TEACHER: 0.524\nEpoch 020 | Train Loss: 311.9448 | Val RMSE vs TRUE: 18.66 | Val R² vs TRUE: 0.306 | Val RMSE vs TEACHER: 11.27 | Val R² vs TEACHER: 0.544\nEpoch 025 | Train Loss: 308.6765 | Val RMSE vs TRUE: 18.60 | Val R² vs TRUE: 0.310 | Val RMSE vs TEACHER: 11.17 | Val R² vs TEACHER: 0.552\nEpoch 030 | Train Loss: 303.5456 | Val RMSE vs TRUE: 18.55 | Val R² vs TRUE: 0.314 | Val RMSE vs TEACHER: 11.05 | Val R² vs TEACHER: 0.562\nEpoch 035 | Train Loss: 297.0408 | Val RMSE vs TRUE: 18.43 | Val R² vs TRUE: 0.323 | Val RMSE vs TEACHER: 10.90 | Val R² vs TEACHER: 0.573\nEpoch 040 | Train Loss: 292.0625 | Val RMSE vs TRUE: 18.47 | Val R² vs TRUE: 0.320 | Val RMSE vs TEACHER: 10.83 | Val R² vs TEACHER: 0.579\nEpoch 045 | Train Loss: 286.2876 | Val RMSE vs TRUE: 18.37 | Val R² vs TRUE: 0.327 | Val RMSE vs TEACHER: 10.72 | Val R² vs TEACHER: 0.587\nEpoch 050 | Train Loss: 278.6634 | Val RMSE vs TRUE: 18.20 | Val R² vs TRUE: 0.339 | Val RMSE vs TEACHER: 10.49 | Val R² vs TEACHER: 0.605\nEpoch 055 | Train Loss: 273.9769 | Val RMSE vs TRUE: 18.36 | Val R² vs TRUE: 0.327 | Val RMSE vs TEACHER: 10.57 | Val R² vs TEACHER: 0.598\nEpoch 060 | Train Loss: 267.5788 | Val RMSE vs TRUE: 18.19 | Val R² vs TRUE: 0.340 | Val RMSE vs TEACHER: 10.35 | Val R² vs TEACHER: 0.615\nEpoch 065 | Train Loss: 253.9043 | Val RMSE vs TRUE: 18.02 | Val R² vs TRUE: 0.352 | Val RMSE vs TEACHER: 10.13 | Val R² vs TEACHER: 0.631\nEpoch 070 | Train Loss: 246.1667 | Val RMSE vs TRUE: 17.97 | Val R² vs TRUE: 0.356 | Val RMSE vs TEACHER: 10.14 | Val R² vs TEACHER: 0.630\nEpoch 075 | Train Loss: 241.3685 | Val RMSE vs TRUE: 17.97 | Val R² vs TRUE: 0.356 | Val RMSE vs TEACHER: 10.00 | Val R² vs TEACHER: 0.640\nEpoch 080 | Train Loss: 238.9627 | Val RMSE vs TRUE: 17.95 | Val R² vs TRUE: 0.357 | Val RMSE vs TEACHER: 10.02 | Val R² vs TEACHER: 0.639\nEarly stopping at epoch 85.\n\nBest validation RMSE vs TRUE (hybrid): 17.952036\n","output_type":"stream"}],"execution_count":15},{"id":"e46bc555","cell_type":"code","source":"# H4: test evaluation for hybrid student\n\nstudent_hybrid.eval()\nwith torch.no_grad():\n    X_test_torch = torch.from_numpy(X_test).float().to(device)\n    test_preds_hybrid = student_hybrid(X_test_torch).cpu().numpy()\n\n# 1) vs TRUE\ntest_rmse_true_h = rmse(y_test, test_preds_hybrid)\ntest_r2_true_h   = r2_score(y_test, test_preds_hybrid)\n\n# 2) vs TEACHER\ntest_rmse_teacher_h = rmse(y_test_teacher, test_preds_hybrid)\ntest_r2_teacher_h   = r2_score(y_test_teacher, test_preds_hybrid)\n\nprint(\"=== Hybrid Student vs TRUE labels ===\")\nprint(f\"Test RMSE: {test_rmse_true_h:.2f}\")\nprint(f\"Test R²  : {test_r2_true_h:.3f}\")\n\nprint(\"\\n=== Hybrid Student vs TEACHER (XGBoost) ===\")\nprint(f\"Test RMSE (student vs teacher preds): {test_rmse_teacher_h:.2f}\")\nprint(f\"Test R²   (student vs teacher preds): {test_r2_teacher_h:.3f}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-12-04T00:00:47.010411Z","iopub.execute_input":"2025-12-04T00:00:47.010815Z","iopub.status.idle":"2025-12-04T00:00:47.030168Z","shell.execute_reply.started":"2025-12-04T00:00:47.010795Z","shell.execute_reply":"2025-12-04T00:00:47.029470Z"},"trusted":true},"outputs":[{"name":"stdout","text":"=== Hybrid Student vs TRUE labels ===\nTest RMSE: 17.64\nTest R²  : 0.369\n\n=== Hybrid Student vs TEACHER (XGBoost) ===\nTest RMSE (student vs teacher preds): 9.92\nTest R²   (student vs teacher preds): 0.651\n","output_type":"stream"}],"execution_count":16},{"id":"f4ca9d78","cell_type":"code","source":"# NIO MODEL: choose the hybrid student MLP\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nnio_model = student_hybrid.to(device)   # <-- this is the model we'll use for NIO\nnio_model.eval()\n\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport numpy as np\n\ndef rmse(y_true, y_pred):\n    return np.sqrt(mean_squared_error(y_true, y_pred))\n\nwith torch.no_grad():\n    X_test_torch = torch.from_numpy(X_test).float().to(device)\n    nio_test_preds = nio_model(X_test_torch).cpu().numpy()\n\nnio_rmse = rmse(y_test, nio_test_preds)\nnio_r2   = r2_score(y_test, nio_test_preds)\n\nprint(\"=== Final NIO model (hybrid MLP) ===\")\nprint(f\"Test RMSE: {nio_rmse:.2f}\")\nprint(f\"Test R²  : {nio_r2:.3f}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-12-04T00:00:47.030891Z","iopub.execute_input":"2025-12-04T00:00:47.031114Z","iopub.status.idle":"2025-12-04T00:00:47.050603Z","shell.execute_reply.started":"2025-12-04T00:00:47.031084Z","shell.execute_reply":"2025-12-04T00:00:47.050103Z"},"trusted":true},"outputs":[{"name":"stdout","text":"=== Final NIO model (hybrid MLP) ===\nTest RMSE: 17.64\nTest R²  : 0.369\n","output_type":"stream"}],"execution_count":17},{"id":"02d0c918","cell_type":"code","source":"# Get feature names from the encoded feature DataFrame\nfeature_names = list(X_encoded.columns)\nprint(\"Number of features:\", len(feature_names))\nprint(feature_names[:10])  # just to see a few\n","metadata":{"execution":{"iopub.status.busy":"2025-12-04T00:00:47.051277Z","iopub.execute_input":"2025-12-04T00:00:47.051616Z","iopub.status.idle":"2025-12-04T00:00:47.055612Z","shell.execute_reply.started":"2025-12-04T00:00:47.051592Z","shell.execute_reply":"2025-12-04T00:00:47.054976Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Number of features: 128\n['Unnamed: 0', 'duration_ms', 'explicit', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness']\n","output_type":"stream"}],"execution_count":18},{"id":"2ffd2f76","cell_type":"code","source":"import joblib\nimport torch\n\nprint(\"Number of features:\", len(feature_names))\n\njoblib.dump(scaler, \"nio_scaler.pkl\")\njoblib.dump(feature_names, \"nio_feature_names.pkl\")\ntorch.save(nio_model.state_dict(), \"nio_model_hybrid.pth\")\n\nprint(\"Saved: nio_scaler.pkl, nio_feature_names.pkl, nio_model_hybrid.pth\")\n","metadata":{"execution":{"iopub.status.busy":"2025-12-04T00:00:47.056343Z","iopub.execute_input":"2025-12-04T00:00:47.056635Z","iopub.status.idle":"2025-12-04T00:00:47.074795Z","shell.execute_reply.started":"2025-12-04T00:00:47.056619Z","shell.execute_reply":"2025-12-04T00:00:47.074119Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Number of features: 128\nSaved: nio_scaler.pkl, nio_feature_names.pkl, nio_model_hybrid.pth\n","output_type":"stream"}],"execution_count":19},{"id":"4b7fe0e1","cell_type":"code","source":"# Helper to reload NIO artifacts later\n\nimport joblib\nimport torch.nn as nn\n\nclass SpotifyNioMLP(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, 768),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(768, 512),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Dropout(0.20),\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(0.10),\n            nn.Linear(128, 1),\n        )\n\n    def forward(self, x):\n        return self.net(x).squeeze(-1)\n\ndef load_nio_artifacts():\n    scaler = joblib.load(\"nio_scaler.pkl\")\n    feature_names = joblib.load(\"nio_feature_names.pkl\")\n\n    input_dim = len(feature_names)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    model = SpotifyNioMLP(input_dim).to(device)\n    state = torch.load(\"nio_model_hybrid.pth\", map_location=device)\n    model.load_state_dict(state)\n    model.eval()\n    return model, scaler, feature_names, device\n\nprint(\"NIO artifacts saving & loader are ready.\")\n","metadata":{"execution":{"iopub.status.busy":"2025-12-04T00:00:47.075514Z","iopub.execute_input":"2025-12-04T00:00:47.075800Z","iopub.status.idle":"2025-12-04T00:00:47.082155Z","shell.execute_reply.started":"2025-12-04T00:00:47.075783Z","shell.execute_reply":"2025-12-04T00:00:47.081416Z"},"trusted":true},"outputs":[{"name":"stdout","text":"NIO artifacts saving & loader are ready.\n","output_type":"stream"}],"execution_count":20},{"id":"285d53de","cell_type":"code","source":"# CELL N1 – Load NIO model + scaler + feature names\n\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport joblib\n\n# Define the same architecture we used for the hybrid student\nclass SpotifyNioMLP(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, 768),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(768, 512),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Dropout(0.20),\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(0.10),\n            nn.Linear(128, 1),\n        )\n\n    def forward(self, x):\n        return self.net(x).squeeze(-1)\n\n\ndef load_nio_artifacts():\n    scaler = joblib.load(\"nio_scaler.pkl\")\n    feature_names = joblib.load(\"nio_feature_names.pkl\")\n\n    input_dim = len(feature_names)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    model = SpotifyNioMLP(input_dim).to(device)\n    state = torch.load(\"nio_model_hybrid.pth\", map_location=device)\n    model.load_state_dict(state)\n    model.eval()\n\n    return model, scaler, feature_names, device\n\nmodel_nio, scaler_nio, feature_names_nio, device = load_nio_artifacts()\n\nprint(\"✅ Loaded NIO model\")\nprint(\"Device        :\", device)\nprint(\"Num features  :\", len(feature_names_nio))\nprint(\"First 10 cols :\", feature_names_nio[:10])\n","metadata":{"execution":{"iopub.status.busy":"2025-12-04T00:00:47.085160Z","iopub.execute_input":"2025-12-04T00:00:47.085719Z","iopub.status.idle":"2025-12-04T00:00:47.113842Z","shell.execute_reply.started":"2025-12-04T00:00:47.085698Z","shell.execute_reply":"2025-12-04T00:00:47.113335Z"},"trusted":true},"outputs":[{"name":"stdout","text":"✅ Loaded NIO model\nDevice        : cuda\nNum features  : 128\nFirst 10 cols : ['Unnamed: 0', 'duration_ms', 'explicit', 'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness']\n","output_type":"stream"}],"execution_count":21},{"id":"478229e2","cell_type":"code","source":"# CELL N2 – Pick one test example and inspect it\n\nimport numpy as np\nimport torch\n\n# Choose an index in the test set\nidx = 0   # you can change this later (0, 10, 100, etc.)\n\n# Get scaled features and true label for that test example\nx0_scaled = X_test[idx:idx+1]          # shape (1, num_features)\ny0_true   = float(y_test[idx])\n\nx0_scaled_t = torch.from_numpy(x0_scaled).float().to(device)\n\n# Model prediction (on scaled input)\nmodel_nio.eval()\nwith torch.no_grad():\n    y0_pred = model_nio(x0_scaled_t).item()\n\nprint(f\"Test example index: {idx}\")\nprint(f\"True popularity   : {y0_true:.1f}\")\nprint(f\"Pred popularity   : {y0_pred:.2f}\")\n\n# Inverse-transform to original feature space for interpretability\nx0_unscaled = scaler_nio.inverse_transform(x0_scaled)[0]\nexample_dict = dict(zip(feature_names_nio, x0_unscaled))\n\n# Show some key audio features (only if they exist in the columns)\nkey_feats = [\n    \"danceability\", \"energy\", \"loudness\", \"speechiness\",\n    \"acousticness\", \"instrumentalness\", \"liveness\",\n    \"valence\", \"tempo\", \"duration_ms\"\n]\n\nprint(\"\\nKey features for this track:\")\nfor f in key_feats:\n    if f in example_dict:\n        print(f\"  {f:15s}: {example_dict[f]:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-12-04T00:00:47.114474Z","iopub.execute_input":"2025-12-04T00:00:47.114686Z","iopub.status.idle":"2025-12-04T00:00:47.122349Z","shell.execute_reply.started":"2025-12-04T00:00:47.114665Z","shell.execute_reply":"2025-12-04T00:00:47.121752Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Test example index: 0\nTrue popularity   : 50.0\nPred popularity   : 44.66\n\nKey features for this track:\n  danceability   : 0.3690\n  energy         : 0.5980\n  loudness       : -6.9840\n  speechiness    : 0.0304\n  acousticness   : 0.0051\n  instrumentalness: -0.0000\n  liveness       : 0.1760\n  valence        : 0.0466\n  tempo          : 148.0140\n  duration_ms    : 440247.0000\n","output_type":"stream"}],"execution_count":22},{"id":"aa1b3e47","cell_type":"code","source":"# CELL N3 – choose which features NIO can change and prepare optimization variables\n\nimport torch\nimport numpy as np\n\n# Features we allow NIO to tweak (continuous, interpretable audio features)\nopt_feature_names = [\n    \"danceability\",\n    \"energy\",\n    \"loudness\",\n    \"speechiness\",\n    \"acousticness\",\n    \"instrumentalness\",\n    \"liveness\",\n    \"valence\",\n    \"tempo\",\n]\n\n# Find their indices in the feature vector\nopt_indices = [feature_names_nio.index(f) for f in opt_feature_names if f in feature_names_nio]\n\nprint(\"Optimizable features and indices:\")\nfor f in opt_feature_names:\n    if f in feature_names_nio:\n        print(f\"  {f:15s} -> idx {feature_names_nio.index(f)}\")\n    else:\n        print(f\"  {f:15s} -> NOT FOUND in feature_names_nio\")\n\nprint(\"\\nTotal optimizable dims:\", len(opt_indices))\n\n# Original scaled vector for this example (from CELL N2)\nx0_scaled_np = x0_scaled.copy()  # shape (1, D)\n\n# Extract just the optimizable dimensions (in *scaled* space)\nx_params_init = x0_scaled_np[:, opt_indices]  # shape (1, k)\n\n# This is what we will actually optimize\nx_params = torch.tensor(\n    x_params_init,\n    dtype=torch.float32,\n    device=device,\n    requires_grad=True\n)\n\nprint(\"x_params shape:\", x_params.shape)\nprint(\"Initial optimizable feature values (scaled):\")\nprint(x_params.detach().cpu().numpy())\n","metadata":{"execution":{"iopub.status.busy":"2025-12-04T00:00:47.123052Z","iopub.execute_input":"2025-12-04T00:00:47.123314Z","iopub.status.idle":"2025-12-04T00:00:47.136978Z","shell.execute_reply.started":"2025-12-04T00:00:47.123291Z","shell.execute_reply":"2025-12-04T00:00:47.136313Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Optimizable features and indices:\n  danceability    -> idx 3\n  energy          -> idx 4\n  loudness        -> idx 6\n  speechiness     -> idx 8\n  acousticness    -> idx 9\n  instrumentalness -> idx 10\n  liveness        -> idx 11\n  valence         -> idx 12\n  tempo           -> idx 13\n\nTotal optimizable dims: 9\nx_params shape: torch.Size([1, 9])\nInitial optimizable feature values (scaled):\n[[-1.139786   -0.17247687  0.2535058  -0.51311016 -0.93167    -0.5041119\n  -0.19725525 -1.6488018   0.8628363 ]]\n","output_type":"stream"}],"execution_count":23},{"id":"a36fda27","cell_type":"code","source":"# CELL N4 – Optimize the 9 audio features (NIO loop)\n\n# Hyperparameters for NIO\nnum_steps = 300\nlr = 0.05\nlambda_l2 = 0.1      # regularization strength to stay close to original (in scaled space)\nclamp_min = -3.0\nclamp_max =  3.0\n\n# Keep a copy of the initial params for the regularization term\nx_params_init_t = torch.tensor(\n    x_params_init,\n    dtype=torch.float32,\n    device=device\n)\n\noptimizer_nio = torch.optim.Adam([x_params], lr=lr)\n\nhistory = []\n\nfor step in range(1, num_steps + 1):\n    optimizer_nio.zero_grad()\n\n    # Build full scaled input: start from original x0, replace only the optimizable indices\n    x_full = torch.from_numpy(x0_scaled_np).float().to(device)  # shape (1, D)\n    x_full = x_full.clone()  # so we can modify it\n    x_full[:, opt_indices] = x_params  # plug in optimized params\n\n    # Predict popularity\n    y_pred = model_nio(x_full)  # shape (1,)\n    # We want to MAXIMIZE y_pred → MINIMIZE (-y_pred)\n    loss_pop = -y_pred.mean()\n\n    # Regularization: keep x_params close to original (in scaled space)\n    l2_term = torch.mean((x_params - x_params_init_t) ** 2)\n    loss = loss_pop + lambda_l2 * l2_term\n\n    # Backprop through inputs\n    loss.backward()\n    optimizer_nio.step()\n\n    # Clamp to keep values in a reasonable scaled range\n    with torch.no_grad():\n        x_params.clamp_(clamp_min, clamp_max)\n\n    # Logging\n    if step == 1 or step % 50 == 0 or step == num_steps:\n        loss_val = float(loss.item())\n        pop_val  = float(y_pred.item())\n        l2_val   = float(l2_term.item())\n        history.append((step, pop_val, loss_val, l2_val))\n        print(f\"Step {step:03d} | Pred popularity: {pop_val:6.2f} | \"\n              f\"Loss: {loss_val:8.4f} | L2: {l2_val:.4f}\")\n\nprint(\"\\nNIO optimization finished.\")\nprint(\"Final optimized scaled params:\")\nprint(x_params.detach().cpu().numpy())\n","metadata":{"execution":{"iopub.status.busy":"2025-12-04T00:00:47.137745Z","iopub.execute_input":"2025-12-04T00:00:47.137949Z","iopub.status.idle":"2025-12-04T00:00:47.884414Z","shell.execute_reply.started":"2025-12-04T00:00:47.137927Z","shell.execute_reply":"2025-12-04T00:00:47.883703Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Step 001 | Pred popularity:  44.66 | Loss: -44.6559 | L2: 0.0000\nStep 050 | Pred popularity:  82.21 | Loss: -81.8328 | L2: 3.8058\nStep 100 | Pred popularity:  89.05 | Loss: -88.4729 | L2: 5.7627\nStep 150 | Pred popularity:  89.06 | Loss: -88.4876 | L2: 5.7563\nStep 200 | Pred popularity:  89.05 | Loss: -88.4713 | L2: 5.7634\nStep 250 | Pred popularity:  89.06 | Loss: -88.4858 | L2: 5.7558\nStep 300 | Pred popularity:  89.05 | Loss: -88.4760 | L2: 5.7541\n\nNIO optimization finished.\nFinal optimized scaled params:\n[[ 0.5770211 -3.         3.        -3.        -3.        -3.\n   3.        -3.         3.       ]]\n","output_type":"stream"}],"execution_count":24},{"id":"d4bbb4fa","cell_type":"code","source":"# CELL N5 – Decode optimized features and compare before vs after\n\nimport numpy as np\nimport torch\n\n# 1) Build full scaled input with optimized params\nx_opt_scaled = x0_scaled_np.copy()  # start from original\nx_opt_scaled[:, opt_indices] = x_params.detach().cpu().numpy()\n\n# 2) Inverse-transform both original and optimized to original feature space\nx0_unscaled = scaler_nio.inverse_transform(x0_scaled_np)[0]\nx_opt_unscaled = scaler_nio.inverse_transform(x_opt_scaled)[0]\n\nbase_dict = dict(zip(feature_names_nio, x0_unscaled))\nopt_dict  = dict(zip(feature_names_nio, x_opt_unscaled))\n\n# 3) Get predicted popularity for optimized track\nx_opt_t = torch.from_numpy(x_opt_scaled).float().to(device)\nmodel_nio.eval()\nwith torch.no_grad():\n    y_opt_pred = model_nio(x_opt_t).item()\n\nprint(\"=== Popularity before vs after NIO ===\")\nprint(f\"True popularity        : {y0_true:.1f}\")\nprint(f\"Pred popularity (orig) : {y0_pred:.2f}\")\nprint(f\"Pred popularity (NIO)  : {y_opt_pred:.2f}\")\n\n# Optionally clamp to [0, 100] just for interpretability\ny_opt_clamped = max(0.0, min(100.0, y_opt_pred))\nprint(f\"Pred popularity (NIO, clamped to 0–100): {y_opt_clamped:.2f}\")\n\n# 4) Show key feature changes\nkey_feats = [\n    \"danceability\", \"energy\", \"loudness\", \"speechiness\",\n    \"acousticness\", \"instrumentalness\", \"liveness\",\n    \"valence\", \"tempo\", \"duration_ms\"\n]\n\nprint(\"\\n=== Key audio features: original vs optimized ===\")\nprint(f\"{'feature':15s}  {'orig':>12s}  {'opt':>12s}  {'Δ (opt - orig)':>15s}\")\nfor f in key_feats:\n    if f in base_dict:\n        orig = base_dict[f]\n        opt  = opt_dict[f]\n        delta = opt - orig\n        print(f\"{f:15s}  {orig:12.4f}  {opt:12.4f}  {delta:15.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-12-04T00:00:47.885161Z","iopub.execute_input":"2025-12-04T00:00:47.885415Z","iopub.status.idle":"2025-12-04T00:00:47.894891Z","shell.execute_reply.started":"2025-12-04T00:00:47.885389Z","shell.execute_reply":"2025-12-04T00:00:47.894350Z"},"trusted":true},"outputs":[{"name":"stdout","text":"=== Popularity before vs after NIO ===\nTrue popularity        : 50.0\nPred popularity (orig) : 44.66\nPred popularity (NIO)  : 89.06\nPred popularity (NIO, clamped to 0–100): 89.06\n\n=== Key audio features: original vs optimized ===\nfeature                  orig           opt   Δ (opt - orig)\ndanceability           0.3690        0.6669           0.2979\nenergy                 0.5980       -0.1132          -0.7112\nloudness              -6.9840        6.8290          13.8130\nspeechiness            0.0304       -0.2325          -0.2629\nacousticness           0.0051       -0.6827          -0.6878\ninstrumentalness       -0.0000       -0.7726          -0.7726\nliveness               0.1760        0.7847           0.6087\nvalence                0.0466       -0.3037          -0.3503\ntempo                148.0140      212.0820          64.0680\nduration_ms       440247.0000   440247.0000           0.0000\n","output_type":"stream"}],"execution_count":25},{"id":"992001ad","cell_type":"code","source":"# CELL N6 – Clamp optimized features to realistic ranges and recompute popularity\n\nimport numpy as np\nimport torch\n\n# 1) Start from the optimized original-space features we already had\nbase_dict = dict(zip(feature_names_nio, x0_unscaled))\nopt_dict  = dict(zip(feature_names_nio, x_opt_unscaled))\n\n# Define realistic ranges for the main audio features\nranges = {\n    \"danceability\":      (0.0, 1.0),\n    \"energy\":            (0.0, 1.0),\n    \"speechiness\":       (0.0, 1.0),\n    \"acousticness\":      (0.0, 1.0),\n    \"instrumentalness\":  (0.0, 1.0),\n    \"liveness\":          (0.0, 1.0),\n    \"valence\":           (0.0, 1.0),\n    \"loudness\":         (-60.0, 0.0),   # dB range\n    \"tempo\":            (60.0, 220.0),  # bpm\n}\n\n# 2) Build a clamped version in original feature space\nopt_clamped_dict = opt_dict.copy()\n\nfor feat, (vmin, vmax) in ranges.items():\n    if feat in opt_clamped_dict:\n        v = opt_clamped_dict[feat]\n        opt_clamped_dict[feat] = max(vmin, min(vmax, v))\n\n# 3) Turn dict back into ordered vector, then scale and predict\nx_opt_clamped_unscaled = np.array(\n    [opt_clamped_dict[f] for f in feature_names_nio]\n).reshape(1, -1)\n\nx_opt_clamped_scaled = scaler_nio.transform(x_opt_clamped_unscaled)\n\nx_opt_clamped_t = torch.from_numpy(x_opt_clamped_scaled).float().to(device)\nmodel_nio.eval()\nwith torch.no_grad():\n    y_opt_clamped_pred = model_nio(x_opt_clamped_t).item()\n\nprint(\"=== Popularity with realistic clamped features ===\")\nprint(f\"Pred popularity (orig)         : {y0_pred:.2f}\")\nprint(f\"Pred popularity (NIO raw)      : {y_opt_pred:.2f}\")\nprint(f\"Pred popularity (NIO clamped)  : {y_opt_clamped_pred:.2f}\")\nprint(\n    \"Pred popularity (NIO clamped, 0–100): \"\n    f\"{max(0.0, min(100.0, y_opt_clamped_pred)):.2f}\"\n)\n\nprint(\"\\n=== Key features: original vs NIO (clamped) ===\")\nheader = \"{:15s}  {:>12s}  {:>12s}  {:>15s}\".format(\n    \"feature\", \"orig\", \"opt_clamp\", \"Δ (opt - orig)\"\n)\nprint(header)\n\nfor f in key_feats:\n    if f in base_dict:\n        orig = base_dict[f]\n        optc = opt_clamped_dict[f]\n        delta = optc - orig\n        line = \"{:15s}  {:12.4f}  {:12.4f}  {:15.4f}\".format(\n            f, orig, optc, delta\n        )\n        print(line)\n","metadata":{"execution":{"iopub.status.busy":"2025-12-04T00:00:47.895669Z","iopub.execute_input":"2025-12-04T00:00:47.896014Z","iopub.status.idle":"2025-12-04T00:00:47.912372Z","shell.execute_reply.started":"2025-12-04T00:00:47.895988Z","shell.execute_reply":"2025-12-04T00:00:47.911609Z"},"trusted":true},"outputs":[{"name":"stdout","text":"=== Popularity with realistic clamped features ===\nPred popularity (orig)         : 44.66\nPred popularity (NIO raw)      : 89.06\nPred popularity (NIO clamped)  : 59.49\nPred popularity (NIO clamped, 0–100): 59.49\n\n=== Key features: original vs NIO (clamped) ===\nfeature                  orig     opt_clamp   Δ (opt - orig)\ndanceability           0.3690        0.6669           0.2979\nenergy                 0.5980        0.0000          -0.5980\nloudness              -6.9840        0.0000           6.9840\nspeechiness            0.0304        0.0000          -0.0304\nacousticness           0.0051        0.0000          -0.0051\ninstrumentalness       -0.0000        0.0000           0.0000\nliveness               0.1760        0.7847           0.6087\nvalence                0.0466        0.0000          -0.0466\ntempo                148.0140      212.0820          64.0680\nduration_ms       440247.0000   440247.0000           0.0000\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"}],"execution_count":26},{"id":"3d5d750c","cell_type":"code","source":"# CELL N7 – Helper: run NIO for a single test example\n\nimport numpy as np\nimport torch\n\n# Just in case, define the same key features list here\nkey_feats = [\n    \"danceability\", \"energy\", \"loudness\", \"speechiness\",\n    \"acousticness\", \"instrumentalness\", \"liveness\",\n    \"valence\", \"tempo\", \"duration_ms\"\n]\n\n# Ranges for clamping in original feature space\nNIO_RANGES = {\n    \"danceability\":      (0.0, 1.0),\n    \"energy\":            (0.0, 1.0),\n    \"speechiness\":       (0.0, 1.0),\n    \"acousticness\":      (0.0, 1.0),\n    \"instrumentalness\":  (0.0, 1.0),\n    \"liveness\":          (0.0, 1.0),\n    \"valence\":           (0.0, 1.0),\n    \"loudness\":         (-60.0, 0.0),\n    \"tempo\":            (60.0, 220.0),\n}\n\n\ndef run_nio_for_index(\n    idx,\n    num_steps=300,\n    lr=0.05,\n    lambda_l2=0.1,\n    clamp_min=-3.0,\n    clamp_max=3.0,\n    verbose=True,\n):\n    \"\"\"\n    Run NIO on one example from X_test / y_test.\n\n    Returns a dict with:\n      - idx, y_true, y_pred_orig, y_pred_nio_raw, y_pred_nio_clamped\n      - base_dict (original features), opt_dict (raw NIO), opt_clamped_dict\n    \"\"\"\n\n    # -------- 1) Base example --------\n    x0_scaled = X_test[idx:idx+1]          # (1, D)\n    y0_true = float(y_test[idx])\n\n    x0_scaled_t = torch.from_numpy(x0_scaled).float().to(device)\n    model_nio.eval()\n    with torch.no_grad():\n        y0_pred = model_nio(x0_scaled_t).item()\n\n    # Original features in real units\n    x0_unscaled = scaler_nio.inverse_transform(x0_scaled)[0]\n    base_dict = dict(zip(feature_names_nio, x0_unscaled))\n\n    # -------- 2) Set up optimizable params (scaled space) --------\n    x_params_init = x0_scaled[:, opt_indices]            # (1, k)\n    x_params = torch.tensor(\n        x_params_init,\n        dtype=torch.float32,\n        device=device,\n        requires_grad=True\n    )\n    x_params_init_t = torch.tensor(\n        x_params_init,\n        dtype=torch.float32,\n        device=device\n    )\n\n    optimizer_nio = torch.optim.Adam([x_params], lr=lr)\n\n    history = []\n\n    # -------- 3) NIO loop --------\n    for step in range(1, num_steps + 1):\n        optimizer_nio.zero_grad()\n\n        # full scaled input\n        x_full = torch.from_numpy(x0_scaled).float().to(device)\n        x_full = x_full.clone()\n        x_full[:, opt_indices] = x_params\n\n        # predicted popularity\n        y_pred = model_nio(x_full)\n        loss_pop = -y_pred.mean()  # maximize y_pred\n\n        # regularization\n        l2_term = torch.mean((x_params - x_params_init_t) ** 2)\n        loss = loss_pop + lambda_l2 * l2_term\n\n        loss.backward()\n        optimizer_nio.step()\n\n        with torch.no_grad():\n            x_params.clamp_(clamp_min, clamp_max)\n\n        if step == 1 or step % 50 == 0 or step == num_steps:\n            history.append(\n                (step, float(y_pred.item()), float(loss.item()), float(l2_term.item()))\n            )\n\n    # -------- 4) Decode NIO result (raw) --------\n    x_opt_scaled = x0_scaled.copy()\n    x_opt_scaled[:, opt_indices] = x_params.detach().cpu().numpy()\n\n    x_opt_unscaled = scaler_nio.inverse_transform(x_opt_scaled)[0]\n    opt_dict = dict(zip(feature_names_nio, x_opt_unscaled))\n\n    x_opt_t = torch.from_numpy(x_opt_scaled).float().to(device)\n    model_nio.eval()\n    with torch.no_grad():\n        y_opt_pred = model_nio(x_opt_t).item()\n\n    # -------- 5) Clamp to realistic ranges in original space --------\n    opt_clamped_dict = opt_dict.copy()\n    for feat, (vmin, vmax) in NIO_RANGES.items():\n        if feat in opt_clamped_dict:\n            v = opt_clamped_dict[feat]\n            opt_clamped_dict[feat] = max(vmin, min(vmax, v))\n\n    x_opt_clamped_unscaled = np.array(\n        [opt_clamped_dict[f] for f in feature_names_nio]\n    ).reshape(1, -1)\n\n    x_opt_clamped_scaled = scaler_nio.transform(x_opt_clamped_unscaled)\n    x_opt_clamped_t = torch.from_numpy(x_opt_clamped_scaled).float().to(device)\n    with torch.no_grad():\n        y_opt_clamped_pred = model_nio(x_opt_clamped_t).item()\n\n    if verbose:\n        print(f\"=== NIO summary for idx {idx} ===\")\n        print(f\"True popularity             : {y0_true:.1f}\")\n        print(f\"Pred popularity (orig)      : {y0_pred:.2f}\")\n        print(f\"Pred popularity (NIO raw)   : {y_opt_pred:.2f}\")\n        print(f\"Pred popularity (NIO clamp) : {y_opt_clamped_pred:.2f}\")\n        print(\"Some steps:\")\n        for (s, yp, ls, l2) in history:\n            print(f\"  step {s:03d} | pred {yp:6.2f} | loss {ls:8.4f} | L2 {l2:.4f}\")\n\n    return {\n        \"idx\": idx,\n        \"y_true\": y0_true,\n        \"y_pred_orig\": y0_pred,\n        \"y_pred_nio_raw\": y_opt_pred,\n        \"y_pred_nio_clamped\": y_opt_clamped_pred,\n        \"base_dict\": base_dict,\n        \"opt_dict\": opt_dict,\n        \"opt_clamped_dict\": opt_clamped_dict,\n        \"history\": history,\n    }\n\nprint(\"✅ run_nio_for_index function defined.\")\n","metadata":{"execution":{"iopub.status.busy":"2025-12-04T00:00:47.913220Z","iopub.execute_input":"2025-12-04T00:00:47.913498Z","iopub.status.idle":"2025-12-04T00:00:47.930312Z","shell.execute_reply.started":"2025-12-04T00:00:47.913475Z","shell.execute_reply":"2025-12-04T00:00:47.929530Z"},"trusted":true},"outputs":[{"name":"stdout","text":"✅ run_nio_for_index function defined.\n","output_type":"stream"}],"execution_count":27},{"id":"b9175969","cell_type":"code","source":"# CELL N8 – Evaluate NIO on multiple test examples\n\nimport random\nimport numpy as np\nimport pandas as pd\n\n# How many test songs to evaluate with NIO\nnum_examples = 30\n\nrandom.seed(0)\nindices = random.sample(range(len(X_test)), num_examples)\n\nresults = []\nprint(f\"Running NIO on {num_examples} random test examples...\\n\")\n\nfor idx in indices:\n    res = run_nio_for_index(idx, verbose=False)\n    results.append(res)\n\n# Build a DataFrame with key metrics\nrows = []\nfor r in results:\n    rows.append({\n        \"idx\": r[\"idx\"],\n        \"y_true\": r[\"y_true\"],\n        \"orig_pred\": r[\"y_pred_orig\"],\n        \"nio_clamped_pred\": r[\"y_pred_nio_clamped\"],\n        \"delta_pred\": r[\"y_pred_nio_clamped\"] - r[\"y_pred_orig\"],\n    })\n\ndf_nio_test = pd.DataFrame(rows)\n\nprint(\"=== First 10 NIO results ===\")\nprint(df_nio_test.head(10))\n\n# Summary statistics\nmean_orig = df_nio_test[\"orig_pred\"].mean()\nmean_nio  = df_nio_test[\"nio_clamped_pred\"].mean()\nmean_delta = df_nio_test[\"delta_pred\"].mean()\nmedian_delta = df_nio_test[\"delta_pred\"].median()\n\nimproved = (df_nio_test[\"delta_pred\"] > 0).mean() * 100\nimproved_2 = (df_nio_test[\"delta_pred\"] > 2).mean() * 100\nworse = (df_nio_test[\"delta_pred\"] < 0).mean() * 100\n\nprint(\"\\n=== NIO overall impact (on these examples) ===\")\nprint(f\"Mean pred (orig)      : {mean_orig:.2f}\")\nprint(f\"Mean pred (NIO clamp) : {mean_nio:.2f}\")\nprint(f\"Mean Δ (NIO - orig)   : {mean_delta:.2f}\")\nprint(f\"Median Δ              : {median_delta:.2f}\")\nprint(f\"% tracks improved     : {improved:.1f}%\")\nprint(f\"% tracks improved >2  : {improved_2:.1f}%\")\nprint(f\"% tracks got worse    : {worse:.1f}%\")\n","metadata":{"execution":{"iopub.status.busy":"2025-12-04T00:00:47.931218Z","iopub.execute_input":"2025-12-04T00:00:47.931502Z","iopub.status.idle":"2025-12-04T00:01:05.995881Z","shell.execute_reply.started":"2025-12-04T00:00:47.931446Z","shell.execute_reply":"2025-12-04T00:01:05.995028Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Running NIO on 30 random test examples...\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"=== First 10 NIO results ===\n     idx  y_true  orig_pred  nio_clamped_pred  delta_pred\n0  12623    49.0  26.382135         58.651276   32.269140\n1  13781    10.0   9.454279         74.568123   65.113844\n2   1326     0.0   6.718862        112.266083  105.547221\n3   8484    46.0  44.036263         61.589630   17.553368\n4  16753    55.0  58.657852         81.372902   22.715050\n5  15922    49.0  42.636627        103.211586   60.574959\n6  13268    12.0  14.291389         32.043793   17.752403\n7   9938    75.0  31.266548         95.321579   64.055031\n8  15617    52.0  25.982153        139.561310  113.579157\n9  11732    49.0  51.322922         80.300209   28.977287\n\n=== NIO overall impact (on these examples) ===\nMean pred (orig)      : 33.13\nMean pred (NIO clamp) : 86.65\nMean Δ (NIO - orig)   : 53.52\nMedian Δ              : 34.90\n% tracks improved     : 100.0%\n% tracks improved >2  : 100.0%\n% tracks got worse    : 0.0%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"}],"execution_count":28}]}